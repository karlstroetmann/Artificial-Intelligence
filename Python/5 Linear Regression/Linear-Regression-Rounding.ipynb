{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style>\n",
    ".container { width:100% }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression: Rounding and Subclassing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we investigate the influence of <em style=\"color:blue;\">rounding</em> and <em style=\"color:blue;\">subclassing</em> on linear regression.  To begin, we import all the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy                as np\n",
    "import matplotlib.pyplot    as plt\n",
    "import seaborn              as sns\n",
    "import sklearn.linear_model as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with artificially generated data.  The independent variable `X` is a `numpy` array \n",
    "of $\\texttt{N}=400$ random numbers that have a <em style=\"color:blue;\">normal</em> distribution with \n",
    "mean $\\mu = 10$ and standard deviation $1$.  The data is created from random numbers.\n",
    "In order to be able to reproduce our results, we use the method `numpy.random.seed`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "N = 400 \n",
    "ùúá = 10\n",
    "X = np.random.randn(N) + ùúá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dependent variable `Y` is created by adding some noise to the independent variable `X`.  This noise is \n",
    "<em style=\"color:blue;\">normally</em> distributed with mean $0$ and standard deviation $0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 0.5 * np.random.randn(len(X))\n",
    "Y = X + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a linear model for `X` and `Y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use **SciKit-Learn** we have to reshape the array X into a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.reshape(X, (len(X), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model and compute its score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = model.fit(X, Y)\n",
    "M.score(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot the data together with the linear model, we extract the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "œë0 = M.intercept_\n",
    "œë1 = M.coef_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot `Y` versus `X` and the linear regression line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xMax = np.max(X) + 0.2\n",
    "xMin = np.min(X) - 0.2\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.set(style='darkgrid')\n",
    "plt.scatter(X, Y, c='b') # 'b' is blue color\n",
    "plt.xlabel('X values')\n",
    "plt.ylabel('true values + noise')\n",
    "plt.title('Influence of rounding on explained variance')\n",
    "plt.show(plt.plot([xMin, xMax], [œë0 + œë1 * xMin, œë0 + œë1 * xMax], c='r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want to study the effect of <em style=\"color:blue;\">rounding</em>, the values of the dependent variable `X` are rounded to the nearest integer.  To this end, the values are transformed to another unit, rounded and then transformed back to the original unkit.  This way we can investigate how the performance of linear regression  degrades if the precision of the measurements of the independent variable is low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.round(X * 0.8) / 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new <em style=\"color:blue;\">linear model</em>, fit it to the data and compute its score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.LinearRegression()\n",
    "M = model.fit(X, Y)\n",
    "M.score(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the performance of the linear model has degraded considerably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "œë0 = M.intercept_\n",
    "œë1 = M.coef_[0]\n",
    "xMax = max(X) + 0.2\n",
    "xMin = min(X) - 0.2\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.set(style='darkgrid')\n",
    "plt.scatter(X, Y, c='b')\n",
    "plt.plot([xMin, xMax], [œë0 + œë1 * xMin, œë0 + œë1 * xMax], c='r')\n",
    "plt.xlabel('rounded X values')\n",
    "plt.ylabel('true X values + noise')\n",
    "plt.title('Influence of rounding on explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we investigate the effect of <em style=\"color:blue;\">subclassing</em>. We will only keep those values such that $X > 11$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selectorX = (X > 11)\n",
    "selectorY = np.reshape(selectorX, (N,))\n",
    "XS = X[selectorX]\n",
    "XS = np.reshape(XS, (len(XS), 1))\n",
    "YS = Y[selectorY]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we fit a linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lm.LinearRegression()\n",
    "M = model.fit(XS, YS)\n",
    "M.score(XS, YS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the performance of linear regression has degraded considerably.  Let's plot this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "œë0 = M.intercept_\n",
    "œë1 = M.coef_[0]\n",
    "xMax = max(XS) + 0.2\n",
    "xMin = min(XS) - 0.2\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.set(style='darkgrid')\n",
    "plt.scatter(XS, YS, c='b')\n",
    "plt.plot([xMin, xMax], [œë0 + œë1 * xMin, œë0 + œë1 * xMax], c='r')\n",
    "plt.xlabel('rounded X values')\n",
    "plt.ylabel('true X values + noise')\n",
    "plt.title('Influence of subclassing on explained variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
