{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open (\"../style.css\", \"r\") as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O6bAYTDQvA9E"
   },
   "source": [
    "# Building a Neural Network with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ofc-wXYMESXW",
    "outputId": "5cbd5e88-7833-44b7-ef23-249306c3eb15"
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import numpy  as np\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following magic command is necessary to prevent the Python kernel to die because of linkage problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env KMP_DUPLICATE_LIB_OK=TRUE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{vectorized_result}(d)$ converts the digit $d \\in \\{0,\\cdots,9\\}$ and returns a NumPy vector $\\mathbf{x}$ of shape $(10, 1)$ such that\n",
    "$$\n",
    "\\mathbf{x}[i] = \n",
    "\\left\\{\n",
    "  \\begin{array}{ll}\n",
    "     1 & \\mbox{if $i = j$;} \\\\\n",
    "     0 & \\mbox{otherwise.}\n",
    "  \\end{array}  \n",
    "\\right.\n",
    "$$\n",
    "This function is used to convert a digit $d$ into the expected output of a neural network that has an output unit for every digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_result(d):\n",
    "    e    = np.zeros((10, ), dtype=np.float32)\n",
    "    e[d] = 1.0\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{load_data}()$ returns a pair of the form\n",
    "$$ (\\texttt{training_data}, \\texttt{test_data}) $$\n",
    "where \n",
    "<ul>\n",
    "<li> $\\texttt{training_data}$ is a list containing 60,000 pairs $(\\textbf{x}, \\textbf{y})$ s.t. $\\textbf{x}$ is a 784-dimensional `numpy.ndarray` containing the input image and $\\textbf{y}$ is a 10-dimensional `numpy.ndarray` corresponding to the correct digit for x.</li>\n",
    "<li> $\\texttt{test_data}$ is a list containing 10,000 pairs $(\\textbf{x}, y)$.  In each case, \n",
    "     $\\textbf{x}$ is a 784-dimensional `numpy.ndarray` containing the input image, \n",
    "     and $y$ is the corresponding digit value.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with gzip.open('../mnist.pkl.gz', 'rb') as f:\n",
    "        train, validate, test = pickle.load(f, encoding=\"latin1\")\n",
    "    X_train = np.array([np.reshape(x, (784, )) for x in train[0]])\n",
    "    X_test  = np.array([np.reshape(x, (784, )) for x in test [0]])\n",
    "    Y_train = np.array([vectorized_result(y) for y in train[1]])\n",
    "    Y_test  = np.array([vectorized_result(y) for y in test [1]])\n",
    "    return (X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ofc-wXYMESXW",
    "outputId": "5cbd5e88-7833-44b7-ef23-249306c3eb15"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see what we have read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Ofc-wXYMESXW",
    "outputId": "5cbd5e88-7833-44b7-ef23-249306c3eb15"
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, Y_train.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we create a neural network with two hidden layers.\n",
    "- The first hidden layer has 60 nodes and uses the <a href=\"https://en.wikipedia.org/wiki/Rectifier_(neural_networks)\">ReLU function</a> \n",
    "  as activation function.\n",
    "- The second hidden layer uses 30 nodes and also uses the ReLu function.  \n",
    "- The output layer uses the <a href=\"https://en.wikipedia.org/wiki/Softmax_function\">softmax function</a> as \n",
    "  activation function.  This function is defined as follows:\n",
    "  $$ \\sigma(\\mathbf{z})_i := \\frac{e^{z_i}}{\\sum\\limits_{d=0}^{9} e^{z_d}}  $$\n",
    "  Here, $N$ is the number of output nodes and $z_i$ is the sum of the inputs of the $i$-th output neuron.\n",
    "  This function guarantees that the outputs of the 10 output nodes can be interpreted as probabilities, since \n",
    "  there sum is equal to $1$.\n",
    "- The <em style=\"color:blue\">loss function</em> used is the <em style=\"color:blue\">cross-entropy</em>.  \n",
    "  If a neuron outputs the value $a$, when it should output the value $y \\in \\{0,1\\}$, the cross entropy cost of \n",
    "  this neuron is defined as\n",
    "  $$ C(a, y) := - y \\cdot \\ln(a) - (1-y)\\cdot \\ln(1-a). $$\n",
    "- The cost function is minimized using stochastic gradient descent with a learning rate of $0.3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17156
    },
    "colab_type": "code",
    "id": "tksxAR3CuorW",
    "outputId": "b80fca9d-5f96-4f51-df34-28cdf5e80f9e"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense( 80, activation='relu', input_dim=784))\n",
    "model.add(keras.layers.Dense( 40, activation='relu'               ))\n",
    "model.add(keras.layers.Dense( 40, activation='relu'               ))\n",
    "model.add(keras.layers.Dense( 10, activation='softmax'            ))\n",
    "model.compile(loss       = 'categorical_crossentropy', \n",
    "              optimizer  = tf.keras.optimizers.SGD(lr=0.3), \n",
    "              metrics    = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17156
    },
    "colab_type": "code",
    "id": "tksxAR3CuorW",
    "outputId": "b80fca9d-5f96-4f51-df34-28cdf5e80f9e"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=30, batch_size=100, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural network hyper-parameters.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
