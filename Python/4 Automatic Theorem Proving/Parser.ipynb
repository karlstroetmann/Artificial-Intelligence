{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open (\"../style.css\", \"r\") as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Simple Parser for Term Rewriting\n",
    "\n",
    "This file implements a parser for terms and equations.  It uses the parser generator `Ply`.  To install [Ply](https://www.dabeaz.com/ply/ply.html), change the cell below into a code cell and execute it.  If the package `ply` is already installed, this command will only produce a message that the package is already installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!conda install -y -c anaconda ply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of the Scanner\n",
    "\n",
    "The scanner that is implemented below recognizes *numbers*, *variable names*, *function names*, and various *operator symbols*.  Variable names have to start with a lower case letter, while function names start with an uppercase letter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.lex as lex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [ 'NUMBER', 'VAR', 'FCT', 'BACKSLASH' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The token `Number` specifies a natural number.  Syntactically, numbers are treated a function symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_NUMBER(t):\n",
    "    r'0|[1-9][0-9]*'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables start with a letter, followed by letters, digits, and underscores. They must be followed by a character that is not an opening parenthesis `(`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_VAR(t):\n",
    "    r'[a-zA-Z][a-zA-Z0-9_]*(?=[^(a-zA-Z0-9_])'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function names start with a letter, followed by letters, digits, and underscores. \n",
    "They have to be followed by an opening parenthesis `(`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_FCT(t):\n",
    "    r'[a-zA-Z][a-zA-Z0-9_]*(?=[(])'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_BACKSLASH(t):\n",
    "    r'\\\\'\n",
    "    return t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Single line comments are supported and work as in `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_COMMENT(t):\n",
    "    r'//[^\\n]*'\n",
    "    t.lexer.lineno += t.value.count('\\n')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The arithmetic operators and a few other symbols are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "literals = ['+', '-', '*', '/', '\\\\', '%', '^', '(', ')', ';', '=', ',']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "White space, i.e. *space characters*, *tabulators*, and *carriage returns* are ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ignore  = ' \\t\\r'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntactically, newline characters are ignored. However, we still need to keep track of them in order to know which line we are in.  This information is needed later for error messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_newline(t):\n",
    "    r'\\n'\n",
    "    t.lexer.lineno += 1\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a `token`, the function `find_colum` returns the column where `token` starts.\n",
    "This is possible, because `token.lexer.lexdata` stores the string that is given to the scanner and `token.lexpos` is the number of characters that precede `token`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_column(token):\n",
    "    program    = token.lexer.lexdata\n",
    "    line_start = program.rfind('\\n', 0, token.lexpos) + 1\n",
    "    return (token.lexpos - line_start) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `t_error` is called for any token `t` that can not be scanned by the lexer.  In this case, `t.value[0]` is the first character that can not be recognized by the scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_error(t):\n",
    "    column = find_column(t)\n",
    "    print(f\"Illegal character '{t.value[0]}' in line {t.lineno}, column {column}.\")\n",
    "    t.lexer.skip(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next assignment is necessary to make the lexer think that the code given above is part of some file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__file__ = 'main'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexer = lex.lex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scanner(file_name):\n",
    "    with open(file_name, 'r') as handle:\n",
    "        program = handle.read() \n",
    "    print(program)\n",
    "    lexer.input(program)\n",
    "    lexer.lineno = 1\n",
    "    return [t for t in lexer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for t in test_scanner('Examples/quasigroup.eqn'):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of the Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following grammar to specify the language that our compiler can translate:\n",
    "```\n",
    "axioms\n",
    "    : equation\n",
    "    | axioms equation \n",
    "    ;\n",
    "    \n",
    "equation \n",
    "    : term '=' term\n",
    "    ;\n",
    " \n",
    "term: term '+'  term                 \n",
    "    | term '-' term               \n",
    "    | term '*' term               \n",
    "    | term '/' term \n",
    "    | term '\\' term\n",
    "    | term '%' term\n",
    "    | term '^' term\n",
    "    | '(' term ')' \n",
    "    | FCT '(' term_list ')'     \n",
    "    | FCT                     \n",
    "    | VAR\n",
    "    ;\n",
    "    \n",
    "term_list\n",
    "    : /* epsilon */\n",
    "    | term\n",
    "    | term ',' ne_term_list\n",
    "    ;\n",
    "    \n",
    "ne_term_list\n",
    "    : term\n",
    "    | term ',' ne_term_list\n",
    "    ;\n",
    "```\n",
    "We will use precedence declarations to resolve the ambiguity that is inherent in this grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ply.yacc as yacc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *start variable* of our grammar is `axioms`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 'axioms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precedence = (\n",
    "    ('nonassoc', '='),\n",
    "    ('left', '+', '-'),\n",
    "    ('left', '*', '/', 'BACKSLASH', '%'),\n",
    "    ('right', '^')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_axioms_one(p):\n",
    "    \"axioms : equation\"\n",
    "    p[0] = ('axioms', p[1])\n",
    "    \n",
    "def p_axioms_more(p):\n",
    "    \"axioms : axioms equation\"\n",
    "    p[0] = p[1] + (p[2],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_equation(p):\n",
    "    \"equation : term '=' term ';'\"\n",
    "    p[0] = ('=', p[1], p[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_term_plus(p):\n",
    "    \"term : term '+' term\"\n",
    "    p[0] = ('+', p[1], p[3])\n",
    "    \n",
    "def p_term_minus(p):\n",
    "    \"term : term '-' term\"\n",
    "    p[0] = ('-', p[1], p[3])\n",
    "    \n",
    "def p_term_times(p):\n",
    "    \"term : term '*' term\"\n",
    "    p[0] = ('*', p[1], p[3])\n",
    "    \n",
    "def p_term_divide(p):\n",
    "    \"term : term '/' term\"\n",
    "    p[0] = ('/', p[1], p[3])\n",
    "    \n",
    "def p_term_backslash(p):\n",
    "    \"term : term BACKSLASH term\"\n",
    "    p[0] = ('\\\\', p[1], p[3])\n",
    "    \n",
    "def p_term_modulo(p):\n",
    "    \"term : term '%' term\"\n",
    "    p[0] = ('%', p[1], p[3])\n",
    "    \n",
    "def p_term_power(p):\n",
    "    \"term : term '^' term\"\n",
    "    p[0] = ('^', p[1], p[3])\n",
    "    \n",
    "def p_term_group(p):\n",
    "    \"term : '(' term ')'\"\n",
    "    p[0] = p[2]\n",
    "\n",
    "def p_term_fct_call(p):\n",
    "    \"term : FCT '(' term_list ')'\"\n",
    "    p[0] = (p[1],) + p[3][1:]\n",
    "\n",
    "def p_term_number(p):\n",
    "    \"term : NUMBER\"\n",
    "    p[0] = (p[1],)\n",
    "\n",
    "def p_term_id(p):\n",
    "    \"term : VAR\"\n",
    "    p[0] = ('$var', p[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_term_list_empty(p):\n",
    "    \"term_list :\"\n",
    "    p[0] = ('.',)\n",
    "    \n",
    "def p_term_list_one(p):\n",
    "    \"term_list : term\"\n",
    "    p[0] = ('.', p[1])     \n",
    "\n",
    "def p_term_list_more(p):\n",
    "    \"term_list : term ',' ne_term_list\"\n",
    "    p[0] = ('.', p[1]) + p[3][1:]     \n",
    "\n",
    "def p_ne_term_list_one(p):\n",
    "    \"ne_term_list : term\"\n",
    "    p[0] = ('.', p[1]) \n",
    "    \n",
    "def p_ne_term_list_more(p):\n",
    "    \"ne_term_list : term ',' ne_term_list\"\n",
    "    p[0] = ('.', p[1]) + p[3][1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_error(p):\n",
    "    if p:\n",
    "        column = find_column(p)\n",
    "        print(f'Syntax error at token \"{p.value}\" in line {p.lineno}, column {column}.')\n",
    "    else:\n",
    "        print('Syntax error at end of input.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the optional argument `write_tables` to `False` **is required** to prevent an obscure bug where the parser generator tries to read an empty parse table.  As we have used *precedence declarations* to resolve all shift/reduce conflicts, the action table should contain no conflict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = yacc.yacc(write_tables=False, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "!cat parser.out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook `AST-2-Dot.ipynb` provides the function `tuple2dot`.  This function can be used to visualize the abstract syntax tree that is generated by the function `yacc.parse`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run AST-2-Dot.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `parse` takes a `file_name` as its sole argument.  The file is read and parsed. \n",
    "The resulting parse tree is visualized using `graphviz`.  It is important to reset the\n",
    "attribute `lineno` of the scanner, for otherwise error messages will not have the correct line numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_parse(file_name):\n",
    "    lexer.lineno = 1\n",
    "    with open(file_name, 'r') as handle:\n",
    "        program = handle.read() \n",
    "    ast = yacc.parse(program)\n",
    "    print(ast)\n",
    "    return tuple2dot(ast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!cat Examples/quasigroup.eqn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_parse('Examples/quasigroup.eqn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `indent` is used to indent the generated assembler commands by preceding them with 8 space characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_file(file_name):\n",
    "    lexer.lineno = 1\n",
    "    with open(file_name, 'r') as handle:\n",
    "        program = handle.read() \n",
    "    AST = yacc.parse(program)\n",
    "    if AST:\n",
    "        _, *L = AST\n",
    "        return L\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse_file('Examples/group-theory.eqn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_equation(s):\n",
    "    lexer.lineno = 1\n",
    "    AST = yacc.parse(s + ';')\n",
    "    if AST:\n",
    "        _, *L = AST\n",
    "        return L[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse_equation('i(x) * x = 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_term(s):\n",
    "    lexer.lineno = 1\n",
    "    AST = yacc.parse(s + '= 1;')\n",
    "    if AST:\n",
    "        _, *L = AST\n",
    "        return L[0][1]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parse_term('i(x) * x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(t):\n",
    "    if isinstance(t, set):\n",
    "        return '{' + ', '.join({ f'{to_str(eq)}' for eq in t }) + '}'\n",
    "    if isinstance(t, list):\n",
    "        return '[' + ', '.join([ f'{to_str(eq)}' for eq in t ]) + ']'\n",
    "    if isinstance(t, dict):\n",
    "        return '{' + ', '.join({ f'{k}: {to_str(v)}' for k, v in t.items() }) + '}'\n",
    "    if isinstance(t, str):\n",
    "        return t\n",
    "    if t[0] == '$var':\n",
    "        return t[1]\n",
    "    if len(t) == 3 and t[0] in ['=']:\n",
    "        _, lhs, rhs = t\n",
    "        return f'{to_str(lhs)} = {to_str(rhs)}'\n",
    "    if t[0] == '\\\\':\n",
    "        op, lhs, rhs = t\n",
    "        return to_str_paren(lhs) + ' \\\\ ' + to_str_paren(rhs)\n",
    "    if len(t) == 3 and t[0] in ['+', '-', '*', '/', '%', '^']:\n",
    "        op, lhs, rhs = t\n",
    "        return f'{to_str_paren(lhs)} {op} {to_str_paren(rhs)}'\n",
    "    f, *Args = t\n",
    "    if Args == []:\n",
    "        return f\n",
    "    return f'{f}({to_str_list(Args)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str_paren(t):\n",
    "    if isinstance(t, str):\n",
    "        return t\n",
    "    if t[0] == '$var':\n",
    "        return t[1]\n",
    "    if len(t) == 3:\n",
    "        op, lhs, rhs = t\n",
    "        return f'({to_str_paren(lhs)} {op} {to_str_paren(rhs)})'\n",
    "    f, *Args = t\n",
    "    if Args == []:\n",
    "        return f\n",
    "    return f'{f}({to_str_list(Args)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str_list(TL):\n",
    "    if TL == []:\n",
    "        return ''\n",
    "    t, *Ts = TL\n",
    "    if Ts == []:\n",
    "        return f'{to_str(t)}'\n",
    "    return f'{to_str(t)}, {to_str_list(Ts)}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
