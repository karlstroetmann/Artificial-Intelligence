{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open (\"../style.css\", \"r\") as file:\n",
    "    css = file.read()\n",
    "HTML(css)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `findMaximum` that is defined below takes four arguments:\n",
    "- `f` is a function of the form $\\texttt{f}: \\mathbb{R}^n \\rightarrow \\mathbb{R}$.\n",
    "   It is assumed that the function `f` is [concave](https://en.wikipedia.org/wiki/Concave_function) and  therefore there is only one      global maximum. \n",
    "- `gradF` is the gradient of the function `f`.\n",
    "- `start` is a `numpy` array of numbers that is used to start the search for a maximum.\n",
    "- `eps` is a small floating point number.  This number controls the precision.\n",
    "  If the values of `f` change less than `eps`, then the algorithm stops.\n",
    "\n",
    "The function `findMaximum` returns a triple of values of the form\n",
    "$$ (x_{max}, \\texttt{fx}, \\texttt{cnt}) $$\n",
    "- $x_{max}$ is an approximation of the position  of the maximum,\n",
    "- $\\texttt{fx}$ is equal to $\\texttt{f}(x_{max})$,\n",
    "- $\\texttt{cnt}$ is the number of iterations that have been performed.\n",
    "\n",
    "The algorithms computes a sequence $(x_n)_n$ that is defined inductively:\n",
    "- $x_0 := \\texttt{start}$,\n",
    "- $x_{n+1} := x_n + \\alpha_n \\cdot \\nabla f(x_n)$.\n",
    "\n",
    "The algorithm given below adjusts the <font color=\"blue\">learning rate</font> $\\alpha$ dynamically: If $f(x_{n+1}) > f(x_n)$, then the learning rate alpha is increased by a factor of $1.2$.  Otherwise, the learning rate is decreased by a factor of $\\frac{1}{2}$.  This way, the algorithm determines the optimal learning rate by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMaximum(f, gradF, start, eps):\n",
    "    x     = start\n",
    "    fx    = f(x)\n",
    "    alpha = 0.1   # learning rate\n",
    "    cnt   = 0     # number of iterations\n",
    "    while True:\n",
    "        cnt += 1\n",
    "        xOld, fOld = x, fx\n",
    "        x  += alpha * gradF(x)\n",
    "        fx  = f(x)\n",
    "        print(f'cnt = {cnt}, f({x}) = {fx}')\n",
    "        print(f'gradient = {gradF(x)}')\n",
    "        if abs(x - xOld) <= abs(x) * eps:\n",
    "            return x, fx, cnt            \n",
    "        if fx <= fOld:    # f didn't increased, learning rate is too high\n",
    "            alpha *= 0.5  # decrease the learning rate\n",
    "            print(f'decrementing: alpha = {alpha}')\n",
    "            x, fx = xOld, fOld    # reset x\n",
    "            continue\n",
    "        else:             # f has increased\n",
    "            alpha *= 1.2  # increase the learning rate\n",
    "            print(f'incrementing: alpha = {alpha}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to find the maximum of the function\n",
    "$$ f(x) := \\sin(x) - \\frac{x^2}{2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.sin(x) - x**2 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(-0.5, 1.8, 0.01)\n",
    "Y = f(X)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.set(style='whitegrid')\n",
    "plt.title('lambda x: sin(x) - x**2/2')\n",
    "plt.axvline(x=0.0, c='k')\n",
    "plt.axhline(y=0.0, c='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.xticks(np.arange(-0.5, 1.81, step=0.1))\n",
    "plt.plot(X, Y, color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, this function has a maximum somewhere between 0.7 and 0.8.  Let us use gradient ascent to find it.  In order to do so, we have to provide the derivative of this function.  We have\n",
    "$$ \\frac{\\mathrm{d}f}{\\mathrm{d}x} = \\cos(x) - x. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fs(x):\n",
    "    return np.cos(x) - x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the derivative together with the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = np.arange(0.4, 1.1, 0.01)\n",
    "Ys = fs(X2)\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.set(style='darkgrid')\n",
    "plt.title('lambda x: sin(x) - x**2/2 and its derivative')\n",
    "plt.axvline(x=0.0, c='k')\n",
    "plt.axhline(y=0.0, c='k')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.xticks(np.arange(-0.5, 1.81, step=0.1))\n",
    "plt.yticks(np.arange(-0.6, 0.61, step=0.1))\n",
    "plt.plot(X, Y, color='b')\n",
    "plt.plot(X2, Ys, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_max, _, cnt = findMaximum(f, fs, 0.0, 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_max, cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum seems to be at $x \\approx 0.739085$.  Let's check the derivative at this position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs(x_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
