{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(open(\"../style.css\", \"r\").read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `nb-mypy` isn't installed, run:\n",
    "```\n",
    "!pip install nb-mypy \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext nb_mypy\n",
    "%nb_mypy On"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Detection  Using the Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of creating a spam detector using the naive Bayes algorithm is split up into four steps.\n",
    "\n",
    "  - Create a set of the most common words occurring in spam and ham (i.e. non-spam) emails.\n",
    "  - For every word occurring in this set, compute the \n",
    "  probability that this word occurs in a spam or ham email.\n",
    "  - Create a function that takes an email and the conditional probabilities computed before and that then computes the probability\n",
    "    that the given email is spam.\n",
    "  - Evaluate the <em style='color:blue;'>precision</em> and the <em style='color:blue;'>recall</em> of the spam classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Create Word Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the module `os` for reading directories and the module `re` for \n",
    "<em style='color:blue;'>regular expressions</em>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An object of class <a href='https://docs.python.org/2/library/collections.html#counter-objects'>`Counter`</a> is a special form of a `dictionary` that is used for counting.  We need a counter to figure out what the most common words are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor `Counter` can be called with an iterable (e.g. a list, a set, or a string) as its argument.\n",
    "It returns a dictionary where the values are the number of occurrences.  The example below counts characters in a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cntr = Counter(\"abracadabra\")\n",
    "Cntr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important method of the class `Counter` is `update`.  If `Ctr` is a counter and `S` is an iterable, then the elements of `S` are added to `Ctr`. If an element `e` occurs `k` times in `S`, then \n",
    "the count of `e` in `Ctr` is incremented by `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cntr.update(\"abba\")\n",
    "Cntr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Email Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory \n",
    "https://github.com/karlstroetmann/Artificial-Intelligence/tree/master/Python/6%20Classification/EmailData\n",
    "contains 960 emails that are divided into four subdirectories:\n",
    "\n",
    "  - `spam-train` contains 350 spam emails for training,\n",
    "  - `ham-train`  contains 350 ham (i.e. non-spam) emails for training,\n",
    "  - `spam-test`  contains 130 spam emails for testing,\n",
    "  - `ham-test`   contains 130 ham  emails for testing.\n",
    "\n",
    "Originally, this data has been collected by **Ion Androutsopoulos**.  I have found this data on a now defunct \n",
    "*open classroom* page on https://online.stanford.edu/free-courses provided by Andrew Ng."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare some variables so this notebook can be adapted to other data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_dir_train: str = 'EmailData/spam-train/'\n",
    "ham__dir_train: str = 'EmailData/ham-train/'\n",
    "spam_dir_test:  str = 'EmailData/spam-test/'\n",
    "ham__dir_test:  str = 'EmailData/ham-test/'\n",
    "Directories: list[str] = [spam_dir_train, ham__dir_train, spam_dir_test, ham__dir_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compute the <em style='color:blue;'>prior probability</em> that an email is ham or spam we need to count the number of spam and ham emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_spam:    int   = len(os.listdir(spam_dir_train)) # number of spam mails\n",
    "no_ham:     int   = len(os.listdir(ham__dir_train)) # number of ham  mails\n",
    "spam_prior: float = no_spam / (no_spam + no_ham)   # probability of a spam mail\n",
    "ham__prior: float = no_ham  / (no_spam + no_ham)   # probability of a ham mail\n",
    "spam_prior, ham__prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have checked that the proportion of spam and ham emails in the test directory is also $1:1$.  If the proportion of spam and ham emails in real life is different from $1:1$, then we would have to use this proportion in the spam filter to be developed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{get_words}(\\texttt{fn})$ takes a filename $\\texttt{fn}$ as its argument.  It reads the file and returns a set of all words that are found in this file.  \n",
    "The words are then transformed to lower case. Since we use a set, words occurring multiple times are only counted once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(fn: str) -> set[str]:\n",
    "    with open(fn, 'r') as file:\n",
    "        text: str = file.read().lower()\n",
    "        return set(re.findall(r\"[\\w']+\", text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test this function with a small example mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat EmailData/ham-train/3-380msg4.txt || or EmailData/ham-train/3-380msg4.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_words('EmailData/ham-train/3-380msg4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `read_all_files` reads all files contained in those directories that are stored in the list `Directories`. \n",
    "It returns a `Counter`.  For every word $w$ this counter contains the number of files that contain the word $w$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_files(Directories: list[str]) -> Counter:\n",
    "    Words: Counter = Counter()\n",
    "    for directory in Directories:\n",
    "        for file_name in os.listdir(directory):\n",
    "            Words.update(get_words(directory + file_name))\n",
    "    return Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Word_Counter` is a dictionary containing all words together with their counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Word_Counter: Counter = read_all_files(Directories)\n",
    "Word_Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The email contains 22770 different words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Word_Counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We investigate how many words only occur in a single email.\n",
    "\n",
    "It wouldn't make sense to use a word as a feature if it only occurs in a single mail.\n",
    "Let's check how many such word exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SingleWords = { w for w in Word_Counter if Word_Counter[w] <= 1 }\n",
    "SingleWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(SingleWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Common_Words` is a list of those words that occur in at least 10 of our emails.\n",
    "The number `min_occurrences` is a *hyper parameter* that should be validated via a validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_occurrences = 10\n",
    "Common_Words: set[str] = { w for w in Word_Counter if Word_Counter[w] >= min_occurrences }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There a 2653 words that occur at least `min_occurrences` times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Common_Words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Conditional Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having computed the most common words, we are now ready to compute the conditional probability that a given word occurs in a spam email."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function $\\texttt{get_common_words}(\\texttt{fn})$ takes a filename $\\texttt{fn}$ \n",
    "as its argument.  It reads the file and returns the set of all words in `Common_Words` that are found in the given file.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_words(fn: str) -> set[str]:\n",
    "    return get_words(fn) & Common_Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test this function for a small email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_common_words('EmailData/ham-train/3-380msg4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `count_common_words` takes a string specifying a `directory`.  It returns a \n",
    "`Counter` that counts how often the words in `Common_Words` occur in any of the files in `directory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_commmon_words(directory: str) -> Counter:\n",
    "    Words: Counter = Counter()\n",
    "    for file_name in os.listdir(directory):\n",
    "        Words.update(get_common_words(directory + file_name))\n",
    "    return Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute `Counter`s that store the number of occurrences in emails for every common word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spam_Counter: Counter = count_commmon_words(spam_dir_train)\n",
    "Spam_Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ham__Counter: Counter = count_commmon_words(ham__dir_train)\n",
    "Ham__Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every common word $w$  we compute the probability that $w$ occurs in a spam or ham email.  The formula for spam is:\n",
    " \n",
    " $$ P(w \\in\\texttt{Spam}) = \\frac{\\mbox{number of spam emails containing $w$}}{\\mbox{number of all spam emails}} $$\n",
    " \n",
    " The formula for ham is similar:\n",
    " \n",
    " $$ P(w \\in\\texttt{Ham}) = \\frac{\\mbox{number of ham emails containing $w$}}{\\mbox{number of all ham emails}} $$\n",
    " \n",
    " However, if we would use this formula, then a common word $w$ that, for some reason, hasn't yet occurred in any spam email, would have a probability of $0$ of occurring in spam email.  Hence, our classifier would never classify an email with the word $w$ as spam.  Since this cannot be right, we assume that there is one additional spam email that contains every common word.  \n",
    "This approach is called\n",
    "*Laplace smoothing* and it changes the formula for $P(w \\in\\texttt{Spam})$ as follows:\n",
    " \n",
    " $$ P(w \\in\\texttt{Spam}) = \\frac{\\mbox{number of spam emails containing $w$ + 1}}{\\mbox{number of all spam emails + 1}} $$\n",
    " \n",
    "Of course, the formula for $P(w \\in\\texttt{Ham})$ is changed in a similar way:\n",
    "\n",
    "$$ P(w \\in\\texttt{Ham}) = \\frac{\\mbox{number of ham emails containing $w$ + 1}}{\\mbox{number of all ham emails + 1}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spam_Probability: dict[str, float] = {}\n",
    "Ham__Probability: dict[str, float] = {}\n",
    "for w in Common_Words:\n",
    "    Spam_Probability[w] = (Spam_Counter[w] + 1) / (no_spam + 1) \n",
    "    Ham__Probability[w] = (Ham__Counter[w] + 1) / (no_ham  + 1) \n",
    "Spam_Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check those common words that have a probability of at least $10\\%$ to occur in a spam mail, but that have a probability of less than $1\\%$ to occur in a ham mail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{ w for w in Common_Words if Spam_Probability[w] > 0.1 and Ham__Probability[w] < 0.01 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the probability that a spam email contains the word `'earn'` is about $15\\%$, while the probability that it occurs in a ham email is $0.55\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spam_Probability['earn'], Ham__Probability['earn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the word `'dollar'` the probability that a spam email contains this word is about $21\\%$, while the probability that this word occurs in a ham email is less than $2\\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Spam_Probability['dollar'], Ham__Probability['dollar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a file name `fn`, the function `log_probabilities` returns a pair of numbers $(p_1, p_2)$ such that.  \n",
    "\n",
    "In order to compute whether a mail is spam or ham we have to compute\n",
    "\n",
    "$$\\arg\\max\\limits_{C \\in \\{\\text{Spam},\\, \\text{Spam}\\}}  \\left(\\prod\\limits_{i=1}^m P(f_i \\;|\\; C)\\right) \\cdot P(C) $$\n",
    "\n",
    "Therefore, we have to check, whether\n",
    "\n",
    "$$ \\left(\\prod\\limits_{i=1}^m P(f_i \\;|\\; \\texttt{Spam})\\right) \\cdot P(\\texttt{Spam}) > \\left(\\prod\\limits_{i=1}^m P(f_i \\;|\\; \\texttt{Ham})\\right) \\cdot P(\\texttt{Ham}) $$\n",
    "\n",
    "holds. When implementing the formula \n",
    "$$\\arg\\max\\limits_{C \\in \\mathcal{C}}  \\left(\\prod\\limits_{i=1}^m P(f_i \\;|\\; C)\\right) \\cdot P(C) $$\n",
    "we have to be careful, because a naive implementation will evaluate the product\n",
    "$$\\prod\\limits_{i=1}^m P(f_i \\;|\\; C)$$\n",
    "as the number $0$ due to numerical underflow.  The trick to compute this product is to remember that\n",
    "$$ \\ln(a \\cdot b) = \\ln(a) + \\ln(b) $$\n",
    "and to transform the product into a sum of logarithms.  As the logarithm is a monotone function, we have \n",
    "\n",
    "$$ \\begin{array}{llcl}\n",
    "  & \\left(\\prod\\limits_{i=1}^m P(f_i \\;|\\; \\texttt{Spam})\\right) \\cdot P(\\texttt{Spam}) & > & \\left(\\prod\\limits_{i=1}^m P(f_i \\;|\\; \\texttt{Ham})\\right) \\cdot P(\\texttt{Ham}) \\\\\n",
    "  \\Leftrightarrow \\qquad &\n",
    "  \\sum\\limits_{i=1}^m \\ln\\bigl(P(f_i \\;|\\; \\texttt{Spam})\\bigr) + \\ln\\bigl(P(\\texttt{Spam})\\bigr) & > & \\sum\\limits_{i=1}^m \\ln\\bigl(P(f_i \\;|\\; \\texttt{Ham})\\bigr) + \\ln\\bigl(P(\\texttt{Ham}) \\bigr)\n",
    "  \\end{array}\n",
    "$$\n",
    "\n",
    "The function `log_probabilities(fn)` takes a filename `fn` as its first argument and returns the pair \n",
    "$$ \\left(\\sum\\limits_{i=1}^m \\ln\\bigl(P(f_i \\;|\\; \\texttt{Spam})\\bigr) + \\ln\\bigl(P(\\texttt{Spam})\\bigr),\\quad\n",
    "         \\sum\\limits_{i=1}^m \\ln\\bigl(P(f_i \\;|\\; \\texttt{Ham})\\bigr) + \\ln\\bigl(P(\\texttt{Ham}) \\bigr) \\right)$$\n",
    "as its result.  It should be noted that these number are not really the logarithms of probabilites.  The reason is that\n",
    "the formula for the probability of a class $C$ is\n",
    "$$\n",
    "\\frac{\\prod\\limits_{i=1}^m P(f_i \\;|\\; C)}{P(f_1 \\wedge \\cdots \\wedge f_m)} \\cdot P(C)\n",
    "$$\n",
    "and we are not computing the denominator $P(f_1 \\wedge \\cdots \\wedge f_m)$.  However, this denominator is the same for spam and ham and hence we don't need it when comparing the respective probabilities.  Therefore, what the function `log_probabilities`is really computing are pairs of *relative logarithmic probabilities*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_probabilities(fn: str) -> tuple[float, float]:\n",
    "    log_p_spam: float = math.log(spam_prior)\n",
    "    log_p_ham:  float = math.log(ham__prior)\n",
    "    words: set[str] = get_common_words(fn)\n",
    "    for w in Common_Words:\n",
    "        if w in words:\n",
    "            log_p_spam += math.log(Spam_Probability[w])\n",
    "            log_p_ham  += math.log(Ham__Probability[w])\n",
    "    return (log_p_ham, log_p_spam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us test this function with a ham email.  Due to privacy concerns, the emails have been reduced to lists of words, which have then been permuted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat EmailData/ham-train/3-430msg1.txt || type EmailData/ham-train/3-430msg1.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probabilities('EmailData/ham-train/3-430msg1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the ham probability is bigger than the spam probability.  Next, we check the general performance of our approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Precision and Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of this algorithm, we need to define two new concepts: *precision* and *recall*.  Let us call the ham emails the *positives*, while the spam emails are called the *negatives*.  Then we define\n",
    "\n",
    "- *true positives*: ham emails that are correctly classified as ham,\n",
    "- *false positives*: spam emails that are falsely classified as ham,\n",
    "- *true negatives*: spam emails that are correctly classified as spam,\n",
    "- *false negatives*: ham emails that are falsely classified as spam.\n",
    "\n",
    "The *precision* of the spam classifier is then defined as\n",
    "$$ \\texttt{precision} = \\frac{\\mbox{number of true positives}}{\\mbox{number of true positives} + \\mbox{number of false positives}} $$\n",
    "Therefore, the *precision* measures the percentage of the ham emails in the set of all emails that are classified as ham. The *recall* of the spam classifier is defined as\n",
    "$$ \\texttt{recall} = \\frac{\\mbox{number of true positives}}{\\mbox{number of true positives} + \\mbox{number of false negatives}} $$\n",
    "Therefore, the *recall* measures the percentage of those ham emails that are indeed classified as ham.\n",
    "\n",
    "Usually, it is very important that the recall is high as we don't want to miss a ham email because our classifier has incorrectly classified it as a spam email.\n",
    "On the other hand, having a high precision is not that important. After all, if $10\\%$ of the emails offered to us as ham are, in fact, spam, we might tolerate this.  However, we would certainly not tolerate missing $10\\%$ of our ham emails because they are incorrectly classified as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `precission_recall` takes two directories as arguments: `spam_dir` is supposed to contain spam emails, while `ham_dir` contains ham emails.  It computes the **precision** and the **recall** of our spam classifier with respect to these test data.  \n",
    "\n",
    "Since it would be quite bad when we misclassify a valid email as spam but we can tolerate an occasional spam email that gets through our filter, we add a third parameter $\\theta$.  We will only classify an email as spam if\n",
    "$$\n",
    "                \\sum\\limits_{i=1}^m \\ln\\bigl(P(f_i \\;|\\; \\texttt{Spam})\\bigr) + \\ln\\bigl(P(\\texttt{Spam})\\bigr) \\; > \\; \n",
    "\\vartheta \\cdot \\sum\\limits_{i=1}^m \\ln\\bigl(P(f_i \\;|\\; \\texttt{Ham})\\bigr) + \\ln\\bigl(P(\\texttt{Ham}) \\bigr)\n",
    "$$\n",
    "The third parameter $\\vartheta$ is the logarithmic threshold. Later, we will use a logarithmic threshold of $0.8$.\n",
    "To make things concrete, assume that\n",
    "* The relative logarithmic probability $p_1$ of a mail being ham is $p_1 = -250$, while\n",
    "* the relative logarithmic probability $p_2$ of this mail being spam is $p_2 = 200$.\n",
    "As we have \n",
    "$$p_1 = -250 < -200 = p_2$$\n",
    "we would classify this mail as spam if we would just compare the relative logarithmic probabilities.\n",
    "However, if we use the logarithmic threshold of $0.8$ we have \n",
    "$$\\vartheta \\cdot p_1 = 0.8 \\cdot (-250) = -200 = p_2 $$ \n",
    "and hence the inequality\n",
    "$$\\vartheta \\cdot p_1 < p_2$$\n",
    "would not be valid.  Therefore, we would conservatively classify the email as ham. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ùúó = 0.8\n",
    "log_p_ham  = -250\n",
    "log_p_spam = -200\n",
    "log_p_spam  > log_p_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_ham * ùúó "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_p_spam  > ùúó * log_p_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precission_recall(spam_dir: str, ham_dir: str, ùúó: float) -> tuple[float, float, float]:\n",
    "    TN: int = 0 # true negatives\n",
    "    FP: int = 0 # false positives\n",
    "    for email in os.listdir(spam_dir):\n",
    "        log_p_ham, log_p_spam = log_probabilities(spam_dir + email)\n",
    "        if log_p_spam > ùúó * log_p_ham:\n",
    "            TN += 1\n",
    "        else:\n",
    "            print(email, log_p_ham, log_p_spam)\n",
    "            FP += 1\n",
    "    FN: int = 0 # false negatives\n",
    "    TP: int = 0 # true positives\n",
    "    for email in os.listdir(ham_dir):\n",
    "        log_p_ham, log_p_spam = log_probabilities(ham_dir + email)\n",
    "        if log_p_spam > ùúó * log_p_ham:\n",
    "            FN += 1\n",
    "            print(email, log_p_ham, log_p_spam)\n",
    "        else:\n",
    "            TP += 1\n",
    "    precision: float = TP / (TP + FP)\n",
    "    recall:    float = TP / (TP + FN)\n",
    "    accuracy:  float = (TN + TP) / (TN + TP + FN + FP)\n",
    "    return precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use $\\vartheta = 0.8$, then we have a *precision* of $95\\%$, and a *total recall* of $100\\%$ on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precission_recall(spam_dir_train, ham__dir_train, 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test set, we still have a *recall* of $100\\%$, but the *precision* drops to $92\\%$, which is still acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precission_recall(spam_dir_test, ham__dir_test, 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
